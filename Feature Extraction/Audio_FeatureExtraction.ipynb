{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This module extracts audio features using OpenSmile\n",
    "\n",
    "emobase.conf is the configuration file used to extract features for both framewise and for entire audio \n",
    "\n",
    "Import necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from os import walk\n",
    "from os.path import splitext\n",
    "from os.path import join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store path for videos from bag of lies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of videos from bag of lies\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "foodir = r'/home/adrikamukherjee/data/BagOfLies/Finalised/'\n",
    "videolist = list()\n",
    "count_bagoflies=0\n",
    "for root, dirs, files in walk(foodir):\n",
    "  for f in files:\n",
    "    if splitext(f)[1].lower() == \".mp4\":\n",
    "      videolist.append(join(root, f))\n",
    "      count_bagoflies +=1\n",
    "print(\"number of videos from bag of lies\")\n",
    "print(count_bagoflies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodir = r'/home/adrikamukherjee/Data_available/Youtube/splitsteal'\n",
    "count_youtube=0\n",
    "for root, dirs, files in walk(foodir):\n",
    "  for f in files:\n",
    "    if splitext(f)[1].lower() == \".mp4\":\n",
    "      videolist.append(join(root, f))\n",
    "      count_youtube +=1\n",
    "print(\"number of videos from splitsteal youtube\")\n",
    "print(count_youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store path for videos youtube data accmulated from 6people, fallon, splitsteal shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of videos from 6people youtube\n",
      "146\n",
      "number of videos from fallon youtube\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "videolist=[]\n",
    "foodir = r'/home/adrikamukherjee/Youtube/6people'\n",
    "count_youtube=0\n",
    "for root, dirs, files in walk(foodir):\n",
    "  for f in files:\n",
    "    if splitext(f)[1].lower() == \".mp4\":\n",
    "      videolist.append(join(root, f))\n",
    "      count_youtube +=1\n",
    "print(\"number of videos from 6people youtube\")\n",
    "print(count_youtube)\n",
    "foodir = r'/home/adrikamukherjee/Youtube/fallon'\n",
    "count_youtube=0\n",
    "for root, dirs, files in walk(foodir):\n",
    "  for f in files:\n",
    "    if splitext(f)[1].lower() == \".mp4\":\n",
    "      videolist.append(join(root, f))\n",
    "      count_youtube +=1\n",
    "print(\"number of videos from fallon youtube\")\n",
    "print(count_youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store path for videos  from Trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of videos from trial data\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "#Execute from commandline\n",
    "#dir_list contains path of all files which contains the audio \n",
    "dir_list=[\"/home/adrikamukherjee/Data_available/Real-life_Deception_Detection_2016/Real-life_Deception_Detection_2016/Clips/Deceptive\"\n",
    "          ,\"/home/adrikamukherjee/Data_available/Real-life_Deception_Detection_2016/Real-life_Deception_Detection_2016/Clips/Truthful\"]\n",
    "count_trial=0\n",
    "for dir in dir_list:\n",
    "    for filename in glob.glob(os.path.join(dir, '*.mp4')):\n",
    "        videolist.append(filename)\n",
    "        count_trial +=1\n",
    "print(\"number of videos from trial data\")\n",
    "print(count_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videolist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all .mp4 files from the above datasets into .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of input and output file path\n",
    "dict_input_output={}\n",
    "output_filename_list=list()\n",
    "wav_bagoflies=0\n",
    "wav_youtube=0\n",
    "wav_trial=0\n",
    "for filename in videolist:\n",
    "    output_filename=\"\"\n",
    "    cmd=\"/home/adrikamukherjee/ffmpeg-git-20200107-amd64-static/ffmpeg -i \" + \"\\\"\" + filename+ \"\\\"\" + \" \"\n",
    "    if \"BagOfLies\" in filename:\n",
    "        x=os.path.split(filename)[0]\n",
    "        x1=os.path.split(filename)[-1]\n",
    "        y=os.path.split(x)[0]\n",
    "        y1=os.path.split(x)[-1]\n",
    "        z1=os.path.split(y)[-1]\n",
    "        output_filename=\"Audio_BagOfLies_\"+z1+\"_\"+y1+\"_\"+x1\n",
    "        wav_bagoflies +=1\n",
    "    if \"Youtube\" in filename:\n",
    "        x=os.path.split(filename)[0]\n",
    "        x1=os.path.split(filename)[-1]\n",
    "        y=os.path.split(x)[0]\n",
    "        y1=os.path.split(x)[-1]\n",
    "        z1=os.path.split(y)[-1]\n",
    "        output_filename=\"Audio_Youtube_\"+z1+\"_\"+y1+\"_\"+x1\n",
    "        wav_youtube +=1\n",
    "    if \"Real-life_Deception_Detection_2016\" in filename:\n",
    "        x=os.path.split(filename)[0]\n",
    "        x1=os.path.split(filename)[-1]\n",
    "        y=os.path.split(x)[0]\n",
    "        y1=os.path.split(x)[-1]\n",
    "        output_filename=\"Audio_reallifedeception_\"+x1\n",
    "        wav_trial +=1\n",
    "    output_filename=output_filename.replace(\".mp4\",\".wav\")\n",
    "    outpath = \"/home/adrikamukherjee/wavfiles/\"+output_filename\n",
    "    cmd=cmd+\"\\\"\"+outpath+\"\\\"\"\n",
    "    x=os.system(cmd)\n",
    "    if(x==0):\n",
    "        dict_input_output[filename]=outpath\n",
    "        output_filename_list.append(outpath)\n",
    "print(\"converted wav files counts are:\")\n",
    "print(\"Bagoflies =\"+str(wav_bagoflies))\n",
    "print(\"youtube = \"+str(wav_youtube))\n",
    "print(\"Trail = \"+str(wav_trial))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "wav_list=[]\n",
    "path=('/home/adrikamukherjee/wavfiles/')\n",
    "for files in glob.glob(os.path.join(path, '*.wav')):\n",
    "    wav_list.append(files)\n",
    "    count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657\n"
     ]
    }
   ],
   "source": [
    "dir=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video\"\n",
    "for filename in glob.glob(os.path.join(dir, '*.arff')):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/home/adrikamukherjee/Data_available/BagOfLies1/Finalised\"\n",
    "for filename in glob.glob(os.path.join(dir, '*.arff')):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate wav files and store in Annotation_audio_features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "head=[]\n",
    "head.append(\"Path_for_mp4_video\")\n",
    "head.append(\"Path_for_wav_file\")\n",
    "head.append(\"csv_file_name\")\n",
    "head.append(\"csv_file_name_path_fullvideo\")\n",
    "head.append(\"csv_file_name_path_perframe\")\n",
    "head.append(\"label\")\n",
    "dir1=\"/home/adrikamukherjee/Audio_features/arff_files_frame_wise/\"\n",
    "dir2=\"/home/adrikamukherjee/Audio_features/arff_files_full_video/\"\n",
    "\n",
    "indexi=0\n",
    "df_input_output=pd.DataFrame(columns = head)\n",
    "for key,value in dict_input_output.items():\n",
    "    df_input_output = df_input_output.append(pd.Series(np.nan, index = head),ignore_index=True)\n",
    "    df_input_output.iloc[indexi, head.index('Path_for_mp4_video')] =  key\n",
    "    df_input_output.iloc[indexi, head.index('Path_for_wav_file')] =  value\n",
    "    csv_file_name = os.path.basename(value)\n",
    "    csv_file_name= csv_file_name.replace(\".wav\",\".csv\")\n",
    "    df_input_output.iloc[indexi, head.index('csv_file_name')] = csv_file_name\n",
    "    df_input_output.iloc[indexi, head.index('csv_file_name_path_fullvideo')] = dir2 + csv_file_name\n",
    "    df_input_output.iloc[indexi, head.index('csv_file_name_path_perframe')] = dir1 + csv_file_name\n",
    "    #annotation_path = \"/home/adrikamukherjee/data/BagOfLies/Annotations.csv\"\n",
    "    #df_bagoflies=pd.read_csv(annotation_path)\n",
    "    if \"Youtube\" in value:\n",
    "        if \"deception\" in value:\n",
    "            df_input_output.iloc[indexi, head.index('label')]=\"Deceptive\"\n",
    "        if \"truth\" in value:\n",
    "            df_input_output.iloc[indexi, head.index('label')]=\"Truthful\"\n",
    "    if \"reallifedeception\" in value:\n",
    "        if \"lie\" in value:\n",
    "            df_input_output.iloc[indexi, head.index('label')]=\"Deceptive\"\n",
    "        if \"truth\" in value:\n",
    "            df_input_output.iloc[indexi, head.index('label')]=\"Truthful\"\n",
    "    if \"BagOfLies\" in value:\n",
    "        x=os.path.split(key)[0]\n",
    "        x1=os.path.split(key)[-1]\n",
    "        y=os.path.split(x)[0]\n",
    "        y1=os.path.split(x)[-1]\n",
    "        z1=os.path.split(y)[-1]\n",
    "        output_filename=\"./Finalised/\"+z1+\"/\"+y1+\"/\"+x1\n",
    "        for index, row in df_bagoflies.iterrows():\n",
    "            if(row[\"video\"]==output_filename):\n",
    "                val=row[\"truth\"]\n",
    "        if(val==0):\n",
    "            df_input_output.iloc[indexi, head.index('label')]=\"Deceptive\"\n",
    "        if(val==1):\n",
    "            df_input_output.iloc[indexi, head.index('label')]=\"Truthful\"\n",
    "    \n",
    "    \n",
    "    indexi +=1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "print(len(df_input_output.index))\n",
    "df_input_output.to_csv(\"Annotation_audio_features.csv\",index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all .flac files of CSC Dataset and store path of these files in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csclist=[]\n",
    "labellist=[]\n",
    "path=r'/home/adrikamukherjee/data/CSC_Deceptice_Speech_LDC2019S09/CDC/data/'\n",
    "for root, dirs, files in walk(path):\n",
    "      for f in files:\n",
    "        if splitext(f)[1].lower() == \".flac\":\n",
    "                csclist.append(join(root, f))\n",
    "        if splitext(f)[1].lower() == \".ltf\":\n",
    "                labellist.append(join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csc_list=[]\n",
    "sublist=[]\n",
    "for filename in csclist:             \n",
    "    x=os.path.split(filename)[0]\n",
    "    x1=os.path.split(filename)[-1]\n",
    "    if \"_R_\" in x1:\n",
    "       new_csc_list.append(filename) \n",
    "    if \"_L_\" in x1:\n",
    "       new_csc_list.append(filename) \n",
    "    y=os.path.split(x)[0]\n",
    "    y1=os.path.split(x)[-1]\n",
    "    if y1 not in sublist:\n",
    "        sublist.append(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert .flac files to .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path=\"/home/adrikamukherjee/Data_available/CSC/\"\n",
    "for file in new_csc_list:\n",
    "    cmd=\"ffmpeg -i \"\n",
    "    cmd = cmd + file\n",
    "    x=os.path.split(file)[0]\n",
    "    x1=os.path.split(file)[-1]\n",
    "    op=x1.replace(\".flac\", \".wav\")\n",
    "    cmd = cmd + \" \"+output_path + op\n",
    "    os.system(cmd)\n",
    "    y=os.path.split(x)[0]\n",
    "    y1=os.path.split(x)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path=\"/home/adrikamukherjee/Data_available/CSC/\"\n",
    "count_csc=0\n",
    "for root, dirs, files in walk(output_path):\n",
    "  for f in files:\n",
    "    if splitext(f)[1].lower() == \".wav\":\n",
    "      count_csc +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_csc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the .wav files based on labels in \".ltf\" file and store the labels in another csv file\n",
    "\n",
    "The Audio from each file is divided into sections and each section is annotated. pydub is used to divide a full audio file into segments and these segment in turn become individual datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"con_ms\" is used to convert time into miliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_ms(v):\n",
    "    i=v.find(\":\")\n",
    "    min=v[0:i]\n",
    "    #ms=int(min)*60000\n",
    "    i2=v.rfind(\".\")\n",
    "    sec=v[i+1:i2]\n",
    "    ms=v[i2+1:len(v)]\n",
    "    milisec=int(min)*60000+int(sec)*1000+int(ms)\n",
    "    return milisec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1093007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_ms(\"18:13.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \".ltf\" file from the CSC data is parsed to find the time intervals and annotations for each audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_path=\"/home/adrikamukherjee/Data_available/CSC/\"\n",
    "annotation_df=pd.read_csv(\"/home/adrikamukherjee/Data_available/Annotation_audio_features.csv\")\n",
    "output_wav_path=\"/home/adrikamukherjee/Data_available/Audio_features/wavfiles/\"\n",
    "count_csc=0\n",
    "c=0\n",
    "for root, dirs, files in walk(input_wav_path):\n",
    "  for f in files:\n",
    "    file_name=input_wav_path+f\n",
    "    ltf_path=\"/home/adrikamukherjee/data/CSC_Deceptice_Speech_LDC2019S09/CDC/data\"\n",
    "    i=f.find(\"_\")\n",
    "    v=f[0:i]\n",
    "    ltf_path=ltf_path+\"/\"+v\n",
    "    v=v+\".ltf\"\n",
    "    ltf_path=ltf_path+\"/\"+v\n",
    "    fileread = open(ltf_path, \"r\")\n",
    "    lines = fileread.readlines()\n",
    "    for val in lines:\n",
    "        x = val.split()\n",
    "        if x[0]==\"TRUTH\":\n",
    "           #annotation_df.index = annotation_df.index + 1\n",
    "           t1 = con_ms(x[1])\n",
    "           t2 = con_ms(x[2])\n",
    "           newAudio = AudioSegment.from_wav(file_name)\n",
    "           newAudio = newAudio[t1:t2]\n",
    "           r_f = f.replace(\".wav\",\"\")\n",
    "           op_f=\"Audio_CSC_\"+r_f+\"_\"+str(c)\n",
    "           c +=1\n",
    "           csv_file_name=op_f+\".csv\"\n",
    "           csv_file_name_path_fullvideo=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video_cscdata/\"+csv_file_name\n",
    "           csv_file_name_path_perframe=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise_cscdata/\"+csv_file_name\n",
    "           op_f=op_f+\".wav\"\n",
    "           op_f= output_wav_path+op_f\n",
    "           newAudio.export(op_f, format=\"wav\")\n",
    "           annotation_df=annotation_df.append({'label' : 'Truthful' ,'csv_file_name':csv_file_name, 'Path_for_wav_file' : op_f, 'csv_file_name_path_fullvideo': csv_file_name_path_fullvideo, 'csv_file_name_path_perframe': csv_file_name_path_perframe} , ignore_index=True)\n",
    "           #annotation_df[\"Path_for_wav_file\"]=op_f\n",
    "           #annotation_df[\"label\"]=\"Truthful\"\n",
    "        if x[0]==\"LIE\":\n",
    "           #annotation_df.index = annotation_df.index + 1\n",
    "           t1 = con_ms(x[1])\n",
    "           t2 = con_ms(x[2])\n",
    "           newAudio = AudioSegment.from_wav(file_name)\n",
    "           newAudio = newAudio[t1:t2]\n",
    "           r_f = f.replace(\".wav\",\"\")\n",
    "           op_f=\"Audio_CSC_\"+r_f+\"_\"+str(c)\n",
    "           c +=1\n",
    "           csv_file_name=op_f+\".csv\"\n",
    "           csv_file_name_path_fullvideo=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video_cscdata/\"+csv_file_name\n",
    "           csv_file_name_path_perframe=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise_cscdata/\"+csv_file_name\n",
    "           op_f=op_f+\".wav\"\n",
    "           op_f= output_wav_path+op_f\n",
    "           newAudio.export(op_f, format=\"wav\")\n",
    "           annotation_df=annotation_df.append({'label' : 'Deceptive' ,'csv_file_name':csv_file_name, 'Path_for_wav_file' : op_f, 'csv_file_name_path_fullvideo': csv_file_name_path_fullvideo, 'csv_file_name_path_perframe': csv_file_name_path_perframe} , ignore_index=True)\n",
    "           #annotation_df[\"Path_for_wav_file\"]=op_f\n",
    "           #annotation_df[\"label\"]=\"Deceptive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df.to_csv(\"/home/adrikamukherjee/Data_available/Audio_features/Final_annotated_file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features from the generated .wav using SMILExtract frame wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657\n"
     ]
    }
   ],
   "source": [
    "dir = \"/home/adrikamukherjee/wavfiles/\"\n",
    "#change outdir=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise/\" for other datasets\n",
    "outdir=\"/home/adrikamukherjee/Audio_features/arff_files_frame_wise/\"\n",
    "list_wav=[]\n",
    "wav_file_count=0\n",
    "for filename in glob.glob(os.path.join(dir, '*.wav')):\n",
    "    list_wav.append(filename)\n",
    "    cmd=\"\"\n",
    "    input_filename=os.path.basename(filename)\n",
    "    output_filename=input_filename.replace(\".wav\",\".arff\")\n",
    "    cmd=\"./SMILExtract -C /home/adrikamukherjee/opensmile-2.3.0/config/emobase.conf -I \" + \"\\\"\" + \"/home/adrikamukherjee/wavfiles/\" + input_filename + \"\\\"\" + \" -O \" + \"\\\"\" + \"/home/adrikamukherjee/Audio_features/arff_files_frame_wise/\" + output_filename + \"\\\"\"\n",
    "    cmd=\"cd /home/adrikamukherjee/opensmile-2.3.0; \"+cmd\n",
    "    x=os.system(cmd)\n",
    "    if(x==0):\n",
    "      wav_file_count +=1  \n",
    "print(wav_file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features from the generated .wav using SMILExtract full video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657\n"
     ]
    }
   ],
   "source": [
    "dir = \"/home/adrikamukherjee/wavfiles/\"\n",
    "#change outdir=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video/\" for other datasets\n",
    "outdir=\"/home/adrikamukherjee/Audio_features/arff_files_full_video/\"\n",
    "wav_file_count=0\n",
    "for filename in glob.glob(os.path.join(dir, '*.wav')):\n",
    "    input_filename=os.path.basename(filename)\n",
    "    output_filename=input_filename.replace(\".wav\",\".arff\")\n",
    "    \n",
    "    cmd=\"./SMILExtract -C /home/adrikamukherjee/opensmile-2.3.0/config/emobase.conf -I \" + \"\\\"\" + \"/home/adrikamukherjee/wavfiles/\" + input_filename + \"\\\"\" + \" -O \" + \"\\\"\" + \"/home/adrikamukherjee/Audio_features/arff_files_full_video/\" + output_filename + \"\\\"\"\n",
    "    cmd=\"cd /home/adrikamukherjee/opensmile-2.3.0; \"+cmd\n",
    "    x=os.system(cmd)\n",
    "    if(x==0):\n",
    "        wav_file_count +=1\n",
    "print(wav_file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert .arff to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir_list=[\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise\",\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video\",\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video_cscdata\",\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise_cscdata/\"]\n",
    "#dir_list=[\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video_cscdata\",\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise_cscdata\"]\n",
    "#for dir in dir_list:\n",
    "dir = \"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise\"   \n",
    "cmd=\"cd \" + dir + \"; python arffTocsv.py\"\n",
    "os.system(cmd)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate individual csv files for full video and combine them to a single file for datasets other than CSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readannotation=pd.read_csv(\"/home/adrikamukherjee/deception_detection/Annotation_audio_features.csv\")\n",
    "df_combined=pd.DataFrame()\n",
    "dir=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video\"\n",
    "for filename in glob.glob(os.path.join(dir, '*.csv')):\n",
    "    file=os.path.basename(filename)\n",
    "    df_readindividual=pd.read_csv(filename)\n",
    "    for index, row in df_readannotation.iterrows():\n",
    "            if(row[\"csv_file_name\"]==file):\n",
    "                val=row[\"label\"]\n",
    "                outputpath=row[\"csv_file_name_path_fullvideo\"]\n",
    "    df_readindividual[\"label\"]=val\n",
    "    del df_readindividual['emotion']\n",
    "    df_readindividual.to_csv(outputpath)\n",
    "    df_combined=df_combined.append(df_readindividual,ignore_index = True)\n",
    "combined_csv_path=dir+\"/Combined_csv_fullvideo.csv\"\n",
    "df_combined.to_csv(combined_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate individual csv files frame wise and combine them to a single file for datasets other than CSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readannotation=pd.read_csv(\"/home/adrikamukherjee/deception_detection/Annotation_audio_features.csv\")\n",
    "df_combined=pd.DataFrame()\n",
    "dir=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise\"\n",
    "for filename in glob.glob(os.path.join(dir, '*.csv')):\n",
    "    file=os.path.basename(filename)\n",
    "    df_readindividual=pd.read_csv(filename)\n",
    "    for index, row in df_readannotation.iterrows():\n",
    "            if(row[\"csv_file_name\"]==file):\n",
    "                val=row[\"label\"]\n",
    "                outputpath=row[\"csv_file_name_path_perframe\"]\n",
    "    df_readindividual[\"label\"]=val\n",
    "    del df_readindividual['emotion']\n",
    "    df_readindividual.to_csv(outputpath)\n",
    "    df_combined=df_combined.append(df_readindividual,ignore_index = True)\n",
    "combined_csv_path=dir+\"/Combined_csv_framewise.csv\"\n",
    "df_combined.to_csv(combined_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate individual csv files for full video and combine them to a single file for CSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readannotation=pd.read_csv(\"/home/adrikamukherjee/Data_available/Audio_features/Final_annotated_file.csv\")\n",
    "df_combined=pd.DataFrame()\n",
    "dir=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video_cscdata\"\n",
    "for filename in glob.glob(os.path.join(dir, '*.csv')):\n",
    "    file=os.path.basename(filename)\n",
    "    \n",
    "    df_readindividual=pd.read_csv(filename)\n",
    "    for index, row in df_readannotation.iterrows():\n",
    "            if(row[\"csv_file_name\"]==file):\n",
    "                val=row[\"label\"]\n",
    "                outputpath=row[\"csv_file_name_path_fullvideo\"]\n",
    "\n",
    "    df_readindividual[\"label\"]=val\n",
    "    del df_readindividual['emotion']\n",
    "    df_readindividual.to_csv(outputpath)\n",
    "    #df_combined=df_combined.append(df_readindividual,ignore_index = True)\n",
    "#combined_csv_path=dir+\"/Combined_csv_fullvideo_csc.csv\"\n",
    "#df_combined.to_csv(combined_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/home/adrikamukherjee/Data_available/Real-life_Deception_Detection_2016/Real-life_Deception_Detection_2016/Clips/Truthful\"\n",
    "for filename in glob.glob(os.path.join(dir, '*.csv')):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate individual csv files framewise and combine them to a single file for CSC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readannotation=pd.read_csv(\"/home/adrikamukherjee/Data_available/Audio_features/Final_annotated_file.csv\")\n",
    "df_combined=pd.DataFrame()\n",
    "dir=\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise_cscdata3\"\n",
    "for filename in glob.glob(os.path.join(dir, '*.csv')):\n",
    "    file=os.path.basename(filename)\n",
    "    df_readindividual=pd.read_csv(filename)\n",
    "    for index, row in df_readannotation.iterrows():\n",
    "            if(row[\"csv_file_name\"]==file):\n",
    "                val=row[\"label\"]\n",
    "                outputpath=row[\"csv_file_name_path_perframe\"]\n",
    "    df_readindividual[\"label\"]=val\n",
    "    del df_readindividual['emotion']\n",
    "    outputpath=outputpath.replace(\"arff_files_frame_wise_cscdata\",\"arff_files_frame_wise_cscdata3\")\n",
    "    df_readindividual.to_csv(outputpath)\n",
    "    #df_combined=df_combined.append(df_readindividual,ignore_index = True)\n",
    "#combined_csv_path=dir+\"/Combined_csv_framewise_csc.csv\"\n",
    "#df_combined.to_csv(combined_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy all .csv files of CSC and non-CSC Dataset for full_video to a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir=[\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video\",\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_full_video_cscdata\"]\n",
    "out_dir=\"/home/adrikamukherjee/Data_available/Audio_features/csv_full_audio\"\n",
    "for dir in list_dir:\n",
    "    for filename in glob.glob(os.path.join(dir, '*.csv')):\n",
    "            file=os.path.basename(filename)\n",
    "            out_path=out_dir+\"/\"+file\n",
    "            cmd=\"cp \"+filename+\" \"+out_path\n",
    "            os.system(cmd)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy all .csv files of CSC and non-CSC Dataset for frame_wise to a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir=[\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise\",\"/home/adrikamukherjee/Data_available/Audio_features/arff_files_frame_wise_cscdata\"]\n",
    "out_dir=\"/home/adrikamukherjee/Data_available/Audio_features/csv_framewise_audio\"\n",
    "for dir in list_dir:\n",
    "    for filename in glob.glob(os.path.join(dir, '*.csv')):\n",
    "            file=os.path.basename(filename)\n",
    "            out_path=out_dir+\"/\"+file\n",
    "            cmd=\"cp \"+filename+\" \"+out_path\n",
    "            os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all data for framewise video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir1=\"/home/adrikamukherjee/Data_available/Audio_features/csv_framewise_audio\"\n",
    "df_frame=pd.DataFrame()\n",
    "for filename in glob.glob(os.path.join(input_dir1, '*.csv')):\n",
    "        file=os.path.basename(filename)\n",
    "        if (file==\"Combined_csv_framewise_csc.csv\" or file == \"Combined_csv_framewise.csv\"):\n",
    "            df=pd.read_csv(filename)\n",
    "            df_frame=df_frame.append(df)       \n",
    "df_frame.to_csv(\"/home/adrikamukherjee/Data_available/Audio_features/csv_framewise_audio/Final_dataset_Audio_framewise.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all data for full video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir2=\"/home/adrikamukherjee/Data_available/Audio_features/csv_full_audio\"\n",
    "df_full=pd.DataFrame()\n",
    "for filename in glob.glob(os.path.join(input_dir1, '*.csv')):\n",
    "        file=os.path.basename(filename)\n",
    "        if (file==\"Combined_csv_fullvideo_csv.csv\" or file == \"Combined_csv_fullvideo.csv\"):\n",
    "            df=pd.read_csv(filename)\n",
    "            df_full=df_full.append(df)\n",
    "df_full.to_csv(\"/home/adrikamukherjee/Data_available/Audio_features/csv_full_audio/Final_dataset_Audio_fullvideo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
